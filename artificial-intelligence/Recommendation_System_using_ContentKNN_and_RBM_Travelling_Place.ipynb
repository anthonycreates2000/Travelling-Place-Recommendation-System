{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv3DVEctuJGs"
      },
      "source": [
        "# Recommendation System using Content Based Filtering and RBM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSi5A-CMSZmR",
        "outputId": "ddc50c64-a4e0-4adc-ef7f-80ed770e49d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.10.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3095461 sha256=8c6376509923fd62e2c178f7b89c5de97f2b87dadcccf869623e574dc173f4dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_76oYMCIuOdV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import heapq\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from surprise import KNNBaseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lskx6Xb3xeLK"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6hDAqOydGqAJ",
        "outputId": "15bf7edb-0ec7-4a48-83b6-9df0c277602f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your kaggle.json file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d5d23f6b-3290-49ef-b4a7-e7c0fe2180b6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d5d23f6b-3290-49ef-b4a7-e7c0fe2180b6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 71 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your kaggle.json file.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwoWq7QDehih",
        "outputId": "afeae6c8-ca6d-4248-c688-55cd2dd03303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbOV-ci6xkMx"
      },
      "source": [
        "Get MovieLens Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU8I7Kppzwn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5105eccc-8ee3-44c0-d22a-d4592317bb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading indonesia-tourism-destination.zip to /content\n",
            "  0% 0.00/158k [00:00<?, ?B/s]\n",
            "100% 158k/158k [00:00<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "! cp ./kaggle.json ~/.kaggle/\n",
        "! kaggle datasets download -d aprabowo/indonesia-tourism-destination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSFtMs7E1zpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455cd272-1915-40b6-f665-2bd2c608d31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./indonesia-tourism-destination.zip\n",
            "  inflating: package_tourism.csv     \n",
            "  inflating: tourism_rating.csv      \n",
            "  inflating: tourism_with_id.csv     \n",
            "  inflating: user.csv                \n"
          ]
        }
      ],
      "source": [
        "! unzip ./indonesia-tourism-destination.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tourism_df = pd.read_csv(\"./drive/MyDrive/Dataset/preprocessed_indonesia_tourism_destination_df.csv\")\n",
        "tourism_2_df = pd.read_csv(\"./tourism_with_id.csv\")\n",
        "rating_df = pd.read_csv(\"./tourism_rating.csv\")"
      ],
      "metadata": {
        "id": "nJLyXcpt444J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9tZWvaHuf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "832a49a8-9d77-42cb-b3e0-9105f91e29ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Place_Id                         Place_Name  \\\n",
              "0         1                   Monumen Nasional   \n",
              "1         2                           Kota Tua   \n",
              "2         3                      Dunia Fantasi   \n",
              "3         4  Taman Mini Indonesia Indah (TMII)   \n",
              "4         5           Atlantis Water Adventure   \n",
              "\n",
              "                                         Description       Category     City  \\\n",
              "0  Monumen Nasional atau yang populer disingkat d...         Budaya  Jakarta   \n",
              "1  Kota tua di Jakarta, yang juga bernama Kota Tu...         Budaya  Jakarta   \n",
              "2  Dunia Fantasi atau disebut juga Dufan adalah t...  Taman Hiburan  Jakarta   \n",
              "3  Taman Mini Indonesia Indah merupakan suatu kaw...  Taman Hiburan  Jakarta   \n",
              "4  Atlantis Water Adventure atau dikenal dengan A...  Taman Hiburan  Jakarta   \n",
              "\n",
              "    Price  Rating       Lat        Long  \n",
              "0   20000     4.6 -6.175392  106.827153  \n",
              "1       0     4.6 -6.137645  106.817125  \n",
              "2  270000     4.6 -6.125312  106.833538  \n",
              "3   10000     4.5 -6.302446  106.895156  \n",
              "4   94000     4.5 -6.124190  106.839134  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b26fcf70-a08a-4469-a083-77f8a5a0387e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>City</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Monumen Nasional</td>\n",
              "      <td>Monumen Nasional atau yang populer disingkat d...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>20000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>-6.175392</td>\n",
              "      <td>106.827153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Kota Tua</td>\n",
              "      <td>Kota tua di Jakarta, yang juga bernama Kota Tu...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>-6.137645</td>\n",
              "      <td>106.817125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dunia Fantasi</td>\n",
              "      <td>Dunia Fantasi atau disebut juga Dufan adalah t...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>270000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>-6.125312</td>\n",
              "      <td>106.833538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
              "      <td>Taman Mini Indonesia Indah merupakan suatu kaw...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>10000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>-6.302446</td>\n",
              "      <td>106.895156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Atlantis Water Adventure</td>\n",
              "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>94000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>-6.124190</td>\n",
              "      <td>106.839134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26fcf70-a08a-4469-a083-77f8a5a0387e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b26fcf70-a08a-4469-a083-77f8a5a0387e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b26fcf70-a08a-4469-a083-77f8a5a0387e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "tourism_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tourism_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "conl0ufLnI-V",
        "outputId": "ab8c5866-6049-4376-9a68-99251b169972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 437 entries, 0 to 436\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Place_Id     437 non-null    int64  \n",
            " 1   Place_Name   437 non-null    object \n",
            " 2   Description  437 non-null    object \n",
            " 3   Category     437 non-null    object \n",
            " 4   City         437 non-null    object \n",
            " 5   Price        437 non-null    int64  \n",
            " 6   Rating       437 non-null    float64\n",
            " 7   Lat          437 non-null    float64\n",
            " 8   Long         437 non-null    float64\n",
            "dtypes: float64(3), int64(2), object(4)\n",
            "memory usage: 30.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jWz_0bS3OET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b76ab12e-5ada-4cda-849a-27a9581cd154"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   User_Id  Place_Id  Place_Ratings\n",
              "0        1       179              3\n",
              "1        1       344              2\n",
              "2        1         5              5\n",
              "3        1       373              3\n",
              "4        1       101              4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddd1bbd2-9004-4465-b19c-385e72603d1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>179</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>344</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>373</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd1bbd2-9004-4465-b19c-385e72603d1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddd1bbd2-9004-4465-b19c-385e72603d1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddd1bbd2-9004-4465-b19c-385e72603d1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "rating_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWynY2yPgSzX",
        "outputId": "22ead3a9-1ee0-4be8-ddaa-a3bb71cc13e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype\n",
            "---  ------         --------------  -----\n",
            " 0   User_Id        10000 non-null  int64\n",
            " 1   Place_Id       10000 non-null  int64\n",
            " 2   Place_Ratings  10000 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 234.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "RLlSxPovgPUR",
        "outputId": "4dc0ff74-1f97-4a22-9be4-26f7a830a074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            User_Id      Place_Id  Place_Ratings\n",
              "count  10000.000000  10000.000000   10000.000000\n",
              "mean     151.292700    219.416400       3.066500\n",
              "std       86.137374    126.228335       1.379952\n",
              "min        1.000000      1.000000       1.000000\n",
              "25%       77.000000    108.750000       2.000000\n",
              "50%      151.000000    220.000000       3.000000\n",
              "75%      226.000000    329.000000       4.000000\n",
              "max      300.000000    437.000000       5.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78aa18b1-eb20-4ae9-81da-0aa0d459b7e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>151.292700</td>\n",
              "      <td>219.416400</td>\n",
              "      <td>3.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>86.137374</td>\n",
              "      <td>126.228335</td>\n",
              "      <td>1.379952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>108.750000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>151.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>226.000000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>300.000000</td>\n",
              "      <td>437.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78aa18b1-eb20-4ae9-81da-0aa0d459b7e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78aa18b1-eb20-4ae9-81da-0aa0d459b7e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78aa18b1-eb20-4ae9-81da-0aa0d459b7e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Modelling."
      ],
      "metadata": {
        "id": "yQt1xpB22U7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyHxZAcaUYge"
      },
      "outputs": [],
      "source": [
        "class TourismDataset:\n",
        "\n",
        "    movieID_to_name = {}\n",
        "    name_to_movieID = {}\n",
        "    ratingsPath = './tourism_rating.csv'\n",
        "    tourismPath = \"./drive/MyDrive/Dataset/preprocessed_indonesia_tourism_destination_df.csv\"\n",
        "\n",
        "    def loadData(self):\n",
        "        self.tourismID_to_name = {}\n",
        "        self.name_to_tourismID = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.tourismPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "          tourismReader = csv.reader(csvfile)\n",
        "          next(tourismReader)  # Skip header line\n",
        "          for row in tourismReader:\n",
        "              tourismID = int(row[0])\n",
        "              tourismName = row[1]\n",
        "              self.tourismID_to_name[tourismID] = tourismName\n",
        "              self.name_to_tourismID[tourismName] = tourismID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getPrice(self):\n",
        "        prices = defaultdict(int)\n",
        "        with open(self.tourismPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "          movieReader = csv.reader(csvfile)\n",
        "          next(movieReader)  # Skip header line\n",
        "          for row in movieReader:\n",
        "            tourismID = int(row[0])\n",
        "            price = row[5]\n",
        "            prices[tourismID] = int(price)\n",
        "        return prices\n",
        "\n",
        "    def getLat(self):\n",
        "        latitudes = defaultdict(int)\n",
        "        with open(self.tourismPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "          movieReader = csv.reader(csvfile)\n",
        "          next(movieReader)  # Skip header line\n",
        "          for row in movieReader:\n",
        "            tourismID = int(row[0])\n",
        "            latitude = row[7]\n",
        "            latitudes[tourismID] = float(latitude)\n",
        "        return latitudes\n",
        "\n",
        "    def getLong(self):\n",
        "        longitudes = defaultdict(int)\n",
        "        with open(self.tourismPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "          movieReader = csv.reader(csvfile)\n",
        "          next(movieReader)  # Skip header line\n",
        "          for row in movieReader:\n",
        "            tourismID = int(row[0])\n",
        "            longitude = row[8]\n",
        "            longitudes[tourismID] = float(longitude)\n",
        "        return longitudes\n",
        "\n",
        "\n",
        "    def getTravellingPlaceName(self, tourismID):\n",
        "        if tourismID in self.tourismID_to_name:\n",
        "            return self.tourismID_to_name[tourismID]\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    def getTravellingPlaceID(self, tourismName):\n",
        "        if tourismName in self.name_to_tourismID:\n",
        "            return self.name_to_tourismID[tourismName]\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    tourismID = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((tourismID, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9nYfRL4SEnF"
      },
      "outputs": [],
      "source": [
        "class EvaluatedAlgorithm:\n",
        "\n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "\n",
        "    def Evaluate(self, evaluationData, doTopN, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
        "        return metrics\n",
        "\n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "\n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPS4Br0_TFea"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "class RBM(object):\n",
        "\n",
        "    def __init__(self, visibleDimensions, epochs=20, hiddenDimensions=50, ratingValues=10, learningRate=0.001, batchSize=100):\n",
        "\n",
        "        self.visibleDimensions = visibleDimensions\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDimensions = hiddenDimensions\n",
        "        self.ratingValues = ratingValues\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "\n",
        "\n",
        "    def Train(self, X):\n",
        "\n",
        "        ops.reset_default_graph()\n",
        "\n",
        "        self.MakeGraph()\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(init)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            np.random.shuffle(X)\n",
        "\n",
        "            trX = np.array(X)\n",
        "            for i in range(0, trX.shape[0], self.batchSize):\n",
        "                self.sess.run(self.update, feed_dict={self.X: trX[i:i+self.batchSize]})\n",
        "\n",
        "            print(\"Trained epoch \", epoch)\n",
        "\n",
        "\n",
        "    def GetRecommendations(self, inputUser):\n",
        "\n",
        "        hidden = tf.nn.sigmoid(tf.matmul(self.X, self.weights) + self.hiddenBias)\n",
        "        visible = tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(self.weights)) + self.visibleBias)\n",
        "\n",
        "        feed = self.sess.run(hidden, feed_dict={ self.X: inputUser} )\n",
        "        rec = self.sess.run(visible, feed_dict={ hidden: feed} )\n",
        "        return rec[0]\n",
        "\n",
        "    def MakeGraph(self):\n",
        "\n",
        "        tf.set_random_seed(0)\n",
        "\n",
        "        # Create variables for the graph, weights and biases\n",
        "        self.X = tf.placeholder(tf.float32, [None, self.visibleDimensions], name=\"X\")\n",
        "\n",
        "        # Initialize weights randomly\n",
        "        maxWeight = -4.0 * np.sqrt(6.0 / (self.hiddenDimensions + self.visibleDimensions))\n",
        "        self.weights = tf.Variable(tf.random_uniform([self.visibleDimensions, self.hiddenDimensions], minval=-maxWeight, maxval=maxWeight), tf.float32, name=\"weights\")\n",
        "\n",
        "        self.hiddenBias = tf.Variable(tf.zeros([self.hiddenDimensions], tf.float32, name=\"hiddenBias\"))\n",
        "        self.visibleBias = tf.Variable(tf.zeros([self.visibleDimensions], tf.float32, name=\"visibleBias\"))\n",
        "\n",
        "        # Perform Gibbs Sampling for Contrastive Divergence, per the paper we assume k=1 instead of iterating over the\n",
        "        # forward pass multiple times since it seems to work just fine\n",
        "\n",
        "        # Forward pass\n",
        "        # Sample hidden layer given visible...\n",
        "        # Get tensor of hidden probabilities\n",
        "        hProb0 = tf.nn.sigmoid(tf.matmul(self.X, self.weights) + self.hiddenBias)\n",
        "        # Sample from all of the distributions\n",
        "        hSample = tf.nn.relu(tf.sign(hProb0 - tf.random_uniform(tf.shape(hProb0))))\n",
        "        # Stitch it together\n",
        "        forward = tf.matmul(tf.transpose(self.X), hSample)\n",
        "\n",
        "        # Backward pass\n",
        "        # Reconstruct visible layer given hidden layer sample\n",
        "        v = tf.matmul(hSample, tf.transpose(self.weights)) + self.visibleBias\n",
        "\n",
        "        # Build up our mask for missing ratings\n",
        "        vMask = tf.sign(self.X) # Make sure everything is 0 or 1\n",
        "        vMask3D = tf.reshape(vMask, [tf.shape(v)[0], -1, self.ratingValues]) # Reshape into arrays of individual ratings\n",
        "        vMask3D = tf.reduce_max(vMask3D, axis=[2], keepdims=True) # Use reduce_max to either give us 1 for ratings that exist, and 0 for missing ratings\n",
        "\n",
        "        # Extract rating vectors for each individual set of 10 rating binary values\n",
        "        v = tf.reshape(v, [tf.shape(v)[0], -1, self.ratingValues])\n",
        "        vProb = tf.nn.softmax(v * vMask3D) # Apply softmax activation function\n",
        "        vProb = tf.reshape(vProb, [tf.shape(v)[0], -1]) # And shove them back into the flattened state. Reconstruction is done now.\n",
        "        # Stitch it together to define the backward pass and updated hidden biases\n",
        "        hProb1 = tf.nn.sigmoid(tf.matmul(vProb, self.weights) + self.hiddenBias)\n",
        "        backward = tf.matmul(tf.transpose(vProb), hProb1)\n",
        "\n",
        "        # Now define what each epoch will do...\n",
        "        # Run the forward and backward passes, and update the weights\n",
        "        weightUpdate = self.weights.assign_add(self.learningRate * (forward - backward))\n",
        "        # Update hidden bias, minimizing the divergence in the hidden nodes\n",
        "        hiddenBiasUpdate = self.hiddenBias.assign_add(self.learningRate * tf.reduce_mean(hProb0 - hProb1, 0))\n",
        "        # Update the visible bias, minimizng divergence in the visible results\n",
        "        visibleBiasUpdate = self.visibleBias.assign_add(self.learningRate * tf.reduce_mean(self.X - vProb, 0))\n",
        "\n",
        "        self.update = [weightUpdate, hiddenBiasUpdate, visibleBiasUpdate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP3q1V7lTxLZ"
      },
      "outputs": [],
      "source": [
        "class RBMAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, epochs=20, hiddenDim=100, learningRate=0.001, batchSize=100, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "        self.tourism_dataset = TourismDataset()\n",
        "        self.tourism_dataset.loadData()\n",
        "        self.stoplist = []\n",
        "\n",
        "    def buildStoplist(self, trainset):\n",
        "        self.stoplistLookup = {}\n",
        "        for iiid in trainset.all_items():\n",
        "            self.stoplistLookup[iiid] = False\n",
        "            tourismID = trainset.to_raw_iid(iiid)\n",
        "            title = self.tourism_dataset.getTravellingPlaceName(int(tourismID))\n",
        "            if (title):\n",
        "                title = title.lower()\n",
        "                for term in self.stoplist:\n",
        "                    if term in title:\n",
        "                        print (\"Blocked \", title)\n",
        "                        self.stoplistLookup[iiid] = True\n",
        "\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        self.buildStoplist(trainset)\n",
        "\n",
        "        numUsers = trainset.n_users\n",
        "        numItems = trainset.n_items\n",
        "\n",
        "        trainingMatrix = np.zeros([numUsers, numItems, 10], dtype=np.float32)\n",
        "\n",
        "        for (uid, iid, rating) in trainset.all_ratings():\n",
        "            if not self.stoplistLookup[iid]:\n",
        "                adjustedRating = int(float(rating)*2.0) - 1\n",
        "                trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
        "\n",
        "        # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
        "        trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
        "\n",
        "        # Create an RBM with (num items * rating values) visible nodes\n",
        "        rbm = RBM(trainingMatrix.shape[1], hiddenDimensions=self.hiddenDim, learningRate=self.learningRate, batchSize=self.batchSize, epochs=self.epochs)\n",
        "        rbm.Train(trainingMatrix)\n",
        "\n",
        "        self.predictedRatings = np.zeros([numUsers, numItems], dtype=np.float32)\n",
        "        for uiid in range(trainset.n_users):\n",
        "            if (uiid % 50 == 0):\n",
        "                print(\"Processing user \", uiid)\n",
        "            recs = rbm.GetRecommendations([trainingMatrix[uiid]])\n",
        "            recs = np.reshape(recs, [numItems, 10])\n",
        "\n",
        "            for itemID, rec in enumerate(recs):\n",
        "                # The obvious thing would be to just take the rating with the highest score:\n",
        "                #rating = rec.argmax()\n",
        "                # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
        "                # The paper suggests performing normalization over K values to get probabilities\n",
        "                # and take the expectation as your prediction, so we'll do that instead:\n",
        "                normalized = self.softmax(rec)\n",
        "                rating = np.average(np.arange(10), weights=normalized)\n",
        "                self.predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "\n",
        "        rating = self.predictedRatings[u, i]\n",
        "\n",
        "        if (rating < 0.001):\n",
        "            raise PredictionImpossible('No valid prediction exists.')\n",
        "\n",
        "        return rating\n",
        "\n",
        "    def GetName(self):\n",
        "      return \"RBM Algorithm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJOPishvUE4x"
      },
      "outputs": [],
      "source": [
        "class ContentKNNAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, k=40, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.k = k\n",
        "\n",
        "    def GetName(self):\n",
        "      return \"Content KNN Algorithm\"\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # Compute item similarity matrix based on content attributes\n",
        "\n",
        "        # Load up genre vectors for every movie\n",
        "        tourism_dataset = TourismDataset()\n",
        "        latitude = tourism_dataset.getLat()\n",
        "        longitude = tourism_dataset.getLong()\n",
        "        price = tourism_dataset.getPrice()\n",
        "\n",
        "        print(\"Computing content-based similarity matrix...\")\n",
        "\n",
        "        # Compute genre distance for every movie combination as a 2x2 matrix\n",
        "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
        "\n",
        "        for thisRating in range(self.trainset.n_items):\n",
        "            if (thisRating % 100 == 0):\n",
        "                print(thisRating, \" of \", self.trainset.n_items)\n",
        "            for otherRating in range(thisRating+1, self.trainset.n_items):\n",
        "                thisMovieID = int(self.trainset.to_raw_iid(thisRating))\n",
        "                otherMovieID = int(self.trainset.to_raw_iid(otherRating))\n",
        "                latitudeSimilarity = self.computeLatitudeSimilarity(thisMovieID, otherMovieID, latitude)\n",
        "                longitudeSimilarity = self.computeLongitudeSimilarity(thisMovieID, otherMovieID, longitude)\n",
        "                priceSimilarity = self.computePriceSimilarity(thisMovieID, otherMovieID, price)\n",
        "\n",
        "                self.similarities[thisRating, otherRating] = latitudeSimilarity * longitudeSimilarity * priceSimilarity\n",
        "                self.similarities[otherRating, thisRating] = self.similarities[thisRating, otherRating]\n",
        "\n",
        "        print(\"...done.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    # def computeCategorySimilarity(self, movie1, movie2, genres):\n",
        "    #     genres1 = genres[movie1]\n",
        "    #     genres2 = genres[movie2]\n",
        "    #     sumxx, sumxy, sumyy = 0, 0, 0\n",
        "    #     for i in range(len(genres1)):\n",
        "    #         x = genres1[i]\n",
        "    #         y = genres2[i]\n",
        "    #         sumxx += x * x\n",
        "    #         sumyy += y * y\n",
        "    #         sumxy += x * y\n",
        "\n",
        "    #     return sumxy/math.sqrt(sumxx*sumyy)\n",
        "\n",
        "    def computePriceSimilarity(self, place_1, place_2, prices):\n",
        "        diff = abs(prices[place_1] - prices[place_2])\n",
        "        sim = math.exp(-diff / 10.0)\n",
        "        return sim\n",
        "\n",
        "    def computeLatitudeSimilarity(self, place_1, place_2, latitude):\n",
        "        diff = abs(latitude[place_1] - latitude[place_2])\n",
        "        sim = math.exp(-diff / 2.0)\n",
        "        return sim\n",
        "\n",
        "    def computeLongitudeSimilarity(self, place_1, place_2, longitude):\n",
        "        diff = abs(longitude[place_1] - longitude[place_2])\n",
        "        sim = math.exp(-diff / 2.0)\n",
        "        return sim\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "\n",
        "        # Build up similarity scores between this item and everything the user rated\n",
        "        neighbors = []\n",
        "        for rating in self.trainset.ur[u]:\n",
        "            similarity = self.similarities[i,rating[0]]\n",
        "            neighbors.append( (similarity, rating[1]) )\n",
        "\n",
        "        # Extract the top-K most-similar ratings\n",
        "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
        "\n",
        "        # Compute average sim score of K neighbors weighted by user ratings\n",
        "        simTotal = weightedSum = 0\n",
        "        for (simScore, rating) in k_neighbors:\n",
        "            if (simScore > 0):\n",
        "                simTotal += simScore\n",
        "                weightedSum += simScore * rating\n",
        "\n",
        "        if (simTotal == 0):\n",
        "            raise PredictionImpossible('No neighbors')\n",
        "\n",
        "        predictedRating = weightedSum / simTotal\n",
        "\n",
        "        return predictedRating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSWCEmyBUviV"
      },
      "outputs": [],
      "source": [
        "class HybridAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, algorithms, weights, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.algorithms = algorithms\n",
        "        self.weights = weights\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        for algorithm in self.algorithms:\n",
        "            algorithm.fit(trainset)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        sumScores = 0\n",
        "        sumWeights = 0\n",
        "\n",
        "        for idx in range(len(self.algorithms)):\n",
        "            sumScores += self.algorithms[idx].estimate(u, i) * self.weights[idx]\n",
        "            sumWeights += self.weights[idx]\n",
        "\n",
        "        return sumScores / sumWeights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jLK3ihVVcpn"
      },
      "outputs": [],
      "source": [
        "class EvaluationData:\n",
        "\n",
        "    def __init__(self, data):\n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "\n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.1, random_state=100)\n",
        "\n",
        "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        #And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "\n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "\n",
        "        #Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "\n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "\n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "\n",
        "    def GetAntiTestSetForUser(self, testSubject):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(testSubject))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                                 i in trainset.all_items() if\n",
        "                                 i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "\n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "\n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "\n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GRh-R5YUwg9"
      },
      "outputs": [],
      "source": [
        "result_df = pd.DataFrame(\n",
        "    columns = [\"epochs\", \"k\", \"RMSE\", \"MAE\"]\n",
        ")\n",
        "\n",
        "class Evaluator:\n",
        "    algorithms = []\n",
        "\n",
        "    def __init__(self, dataset, params):\n",
        "        ed = EvaluationData(dataset)\n",
        "        self.dataset = ed\n",
        "        self.params = params\n",
        "\n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "\n",
        "    def Evaluate(self, doTopN):\n",
        "        global result_df\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        for (name, metrics) in results.items():\n",
        "          print(f\"{name}: \")\n",
        "          print(f\"\"\"Param 1: {self.params[\"epochs\"]}\"\"\")\n",
        "          print(f\"\"\"Param 2: {self.params[\"k\"]}\"\"\")\n",
        "          print(f\"\"\"RMSE: {metrics[\"RMSE\"]}\"\"\")\n",
        "          print(f\"\"\"MAE: {metrics[\"MAE\"]}\"\"\")\n",
        "          result_df_new = pd.DataFrame(\n",
        "            {\n",
        "              \"epochs\": self.params[\"epochs\"],\n",
        "              \"k\": self.params[\"k\"],\n",
        "              \"RMSE\": [metrics[\"RMSE\"]],\n",
        "              \"MAE\": [metrics[\"MAE\"]],\n",
        "            }\n",
        "          )\n",
        "          result_df_2 = result_df.append(result_df_new, ignore_index = True)\n",
        "          result_df = result_df_2\n",
        "\n",
        "        print(\"Legend:\")\n",
        "        print(f\"\"\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\"\"\")\n",
        "        print(f\"\"\"MAE: (Mean Absolute Error. Lower values mean better accuracy.\"\"\")\n",
        "\n",
        "    def SampleTopNRecs(self, tourism_data, testSubject=3, k=10):\n",
        "\n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.GetName())\n",
        "\n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.GetFullTrainSet()\n",
        "            algo.GetAlgorithm().fit(trainSet)\n",
        "\n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.GetAntiTestSetForUser(testSubject)\n",
        "\n",
        "            predictions = algo.GetAlgorithm().test(testSet)\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            print (\"\\nWe recommend:\")\n",
        "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "                intMovieID = int(movieID)\n",
        "                recommendations.append((intMovieID, estimatedRating))\n",
        "\n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for ratings in recommendations[:10]:\n",
        "                print(tourism_data.getTravellingPlaceName(ratings[0]), ratings[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps8NBC-WR9de"
      },
      "outputs": [],
      "source": [
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXqJGlwRV8eL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005adee6-d90c-4b74-fcc1-b9fbd01d6bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading movie ratings...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 10\n",
            "Param 2: 9\n",
            "RMSE: 1.4264615093355715\n",
            "MAE: 1.2078148984547787\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 10\n",
            "Param 2: 10\n",
            "RMSE: 1.4259833948913452\n",
            "MAE: 1.2074457357604738\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 10\n",
            "Param 2: 11\n",
            "RMSE: 1.4263928957567358\n",
            "MAE: 1.2077217581359938\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 11\n",
            "Param 2: 9\n",
            "RMSE: 1.4258047041603916\n",
            "MAE: 1.2071802115788446\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 11\n",
            "Param 2: 10\n",
            "RMSE: 1.4257227072656975\n",
            "MAE: 1.2070886230434363\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 11\n",
            "Param 2: 11\n",
            "RMSE: 1.4262258367009994\n",
            "MAE: 1.2073790719286073\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 12\n",
            "Param 2: 9\n",
            "RMSE: 1.4252631984605553\n",
            "MAE: 1.2065434016337382\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 12\n",
            "Param 2: 10\n",
            "RMSE: 1.4254912985533046\n",
            "MAE: 1.2066589421662068\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n",
            "Loading movie ratings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Hybrid: \n",
            "Param 1: 12\n",
            "Param 2: 11\n",
            "RMSE: 1.4255055609565408\n",
            "MAE: 1.2067356352893903\n",
            "Legend:\n",
            "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE: (Mean Absolute Error. Lower values mean better accuracy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-197-3f1ecbd74519>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df_2 = result_df.append(result_df_new, ignore_index = True)\n"
          ]
        }
      ],
      "source": [
        "num_epochs = [10, 11, 12]\n",
        "k_s = [9, 10, 11]\n",
        "\n",
        "def LoadTourismData():\n",
        "    tourism_dataset = TourismDataset()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = tourism_dataset.loadData()\n",
        "    return (tourism_dataset, data)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "for epoch in num_epochs:\n",
        "  for k in k_s:\n",
        "    # Load up common data set for the recommender algorithms\n",
        "    (tourism_dataset, evaluationData) = LoadTourismData()\n",
        "\n",
        "    params = {\n",
        "        \"epochs\": epoch,\n",
        "        \"k\": k,\n",
        "    }\n",
        "    # Construct an Evaluator to evaluate them\n",
        "    evaluator = Evaluator(evaluationData, params)\n",
        "\n",
        "    #Simple RBM\n",
        "    SimpleRBM = RBMAlgorithm(epochs = epoch)\n",
        "    #Content\n",
        "    ContentKNN = ContentKNNAlgorithm(k = k)\n",
        "\n",
        "    #Combine them\n",
        "    Hybrid = HybridAlgorithm([SimpleRBM, ContentKNN], [0.5, 0.5])\n",
        "\n",
        "\n",
        "    evaluator.AddAlgorithm(Hybrid, \"Hybrid\")\n",
        "\n",
        "    # Fight!\n",
        "    evaluator.Evaluate(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv(\"result_contentknn_and_rbm.csv\", sep = ';', decimal=',', index = False)\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "4DD5pfw3sVCs",
        "outputId": "7fb2159e-dddf-4764-b369-eaa30ee2f959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  epochs   k      RMSE       MAE\n",
              "0     10   9  1.426462  1.207815\n",
              "1     10  10  1.425983  1.207446\n",
              "2     10  11  1.426393  1.207722\n",
              "3     11   9  1.425805  1.207180\n",
              "4     11  10  1.425723  1.207089\n",
              "5     11  11  1.426226  1.207379\n",
              "6     12   9  1.425263  1.206543\n",
              "7     12  10  1.425491  1.206659\n",
              "8     12  11  1.425506  1.206736"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c157f5d1-d79f-47bf-aa6c-c9642d367cdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>k</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1.426462</td>\n",
              "      <td>1.207815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1.425983</td>\n",
              "      <td>1.207446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>1.426393</td>\n",
              "      <td>1.207722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>1.425805</td>\n",
              "      <td>1.207180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>1.425723</td>\n",
              "      <td>1.207089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>1.426226</td>\n",
              "      <td>1.207379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>1.425263</td>\n",
              "      <td>1.206543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>1.425491</td>\n",
              "      <td>1.206659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>1.425506</td>\n",
              "      <td>1.206736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c157f5d1-d79f-47bf-aa6c-c9642d367cdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c157f5d1-d79f-47bf-aa6c-c9642d367cdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c157f5d1-d79f-47bf-aa6c-c9642d367cdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.SampleTopNRecs(tourism_dataset)"
      ],
      "metadata": {
        "id": "G8TnhmwzrXXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba59fbb8-83c5-4465-c9e0-6597a7cb248e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6284748792043504\n",
            "Situs Warungboto 3.6070450928997966\n",
            "Ledok Sambi 3.597935162524959\n",
            "Nol Kilometer Jl.Malioboro 3.595413692740678\n",
            "Desa Wisata Sungai Code Jogja Kota 3.584263586757965\n",
            "Alun-alun Utara Keraton Yogyakarta 3.584039574964732\n",
            "Pasar Kebon Empring Bintaran 3.579497576294095\n",
            "Kampung Wisata Kadipaten 3.578321360523313\n",
            "Bentara Budaya Yogyakarta (BBY) 3.5766457493429433\n",
            "Alun Alun Selatan Yogyakarta 3.5757464629960576\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6217919095039095\n",
            "Situs Warungboto 3.5883332702110904\n",
            "Ledok Sambi 3.5856442457014306\n",
            "Nol Kilometer Jl.Malioboro 3.578022100416534\n",
            "Alun-alun Utara Keraton Yogyakarta 3.5662934439019165\n",
            "Pasar Kebon Empring Bintaran 3.566026650890098\n",
            "Desa Wisata Sungai Code Jogja Kota 3.565653584590014\n",
            "Bentara Budaya Yogyakarta (BBY) 3.5622429778504303\n",
            "Alun Alun Selatan Yogyakarta 3.5620724363642986\n",
            "Gedung Agung Yogyakarta 3.5600175174877897\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6105502350806917\n",
            "Situs Warungboto 3.589944383759369\n",
            "Ledok Sambi 3.5865448718839867\n",
            "Nol Kilometer Jl.Malioboro 3.576006867376678\n",
            "Alun-alun Utara Keraton Yogyakarta 3.568883265717407\n",
            "Desa Wisata Sungai Code Jogja Kota 3.568774602999743\n",
            "Kampung Wisata Rejowinangun 3.5622494496812145\n",
            "Bentara Budaya Yogyakarta (BBY) 3.5610331227707794\n",
            "Pasar Kebon Empring Bintaran 3.5581177105748516\n",
            "Kawasan Malioboro 3.5554115222267475\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6305906056752977\n",
            "Ledok Sambi 3.6170132980153764\n",
            "Situs Warungboto 3.616359749157426\n",
            "Nol Kilometer Jl.Malioboro 3.5961592276375285\n",
            "Desa Wisata Sungai Code Jogja Kota 3.5853020188792417\n",
            "Pasar Kebon Empring Bintaran 3.5832604175187655\n",
            "Keraton Surabaya 3.5813085534604383\n",
            "Kampung Wisata Kadipaten 3.5804850091286595\n",
            "Alun-alun Utara Keraton Yogyakarta 3.579579478605479\n",
            "Alun Alun Selatan Yogyakarta 3.5760516387773076\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6261037095069613\n",
            "Situs Warungboto 3.593307754654755\n",
            "Ledok Sambi 3.591945410328506\n",
            "Pasar Kebon Empring Bintaran 3.5842787852132183\n",
            "Nol Kilometer Jl.Malioboro 3.578804113355987\n",
            "Desa Wisata Sungai Code Jogja Kota 3.572472475161608\n",
            "Alun-alun Utara Keraton Yogyakarta 3.571697797043701\n",
            "Kampung Wisata Rejowinangun 3.570697692822389\n",
            "Kampung Wisata Kadipaten 3.5668280148043463\n",
            "Keraton Surabaya 3.5624024593013455\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.611141393947574\n",
            "Situs Warungboto 3.5959544393013614\n",
            "Ledok Sambi 3.5929549938017113\n",
            "Nol Kilometer Jl.Malioboro 3.587132312742584\n",
            "Alun-alun Utara Keraton Yogyakarta 3.574660743935486\n",
            "Desa Wisata Sungai Code Jogja Kota 3.5743776780272087\n",
            "Bentara Budaya Yogyakarta (BBY) 3.5630950858521393\n",
            "Kampung Wisata Kadipaten 3.562618019534571\n",
            "Pasar Kebon Empring Bintaran 3.562372528537498\n",
            "Alun Alun Selatan Yogyakarta 3.560738603623515\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.635078239380437\n",
            "Situs Warungboto 3.6155566361737224\n",
            "Ledok Sambi 3.606089197139522\n",
            "Desa Wisata Sungai Code Jogja Kota 3.596795105694122\n",
            "Pasar Kebon Empring Bintaran 3.596521854934842\n",
            "Nol Kilometer Jl.Malioboro 3.5941660483162394\n",
            "Alun-alun Utara Keraton Yogyakarta 3.589299446447581\n",
            "Keraton Surabaya 3.585554788354237\n",
            "Taman Keputran 3.584977796813608\n",
            "Gedung Agung Yogyakarta 3.581354168993657\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.6180995209693636\n",
            "Situs Warungboto 3.5979340287636417\n",
            "Nol Kilometer Jl.Malioboro 3.5933166522658992\n",
            "Pasar Kebon Empring Bintaran 3.58617576263784\n",
            "Ledok Sambi 3.5850031381422265\n",
            "Desa Wisata Sungai Code Jogja Kota 3.5771523934507927\n",
            "Alun-alun Utara Keraton Yogyakarta 3.570163692696472\n",
            "Gedung Agung Yogyakarta 3.5668850454495207\n",
            "Alun Alun Selatan Yogyakarta 3.5653865738231\n",
            "Bentara Budaya Yogyakarta (BBY) 3.5653570821213654\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Computing content-based similarity matrix...\n",
            "0  of  437\n",
            "100  of  437\n",
            "200  of  437\n",
            "300  of  437\n",
            "400  of  437\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Geoforest Watu Payung Turunan 3.615181635189029\n",
            "Situs Warungboto 3.5980829211662906\n",
            "Ledok Sambi 3.597202897625564\n",
            "Nol Kilometer Jl.Malioboro 3.5864119310058284\n",
            "Desa Wisata Sungai Code Jogja Kota 3.579404256930407\n",
            "Alun-alun Utara Keraton Yogyakarta 3.574055160744568\n",
            "Pasar Kebon Empring Bintaran 3.571927510722862\n",
            "Kampung Wisata Rejowinangun 3.565309790562562\n",
            "Bentara Budaya Yogyakarta (BBY) 3.563056700460904\n",
            "Kampung Wisata Kadipaten 3.5620504641070196\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}